{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Prerequisties for SageMaker Train and Deploy\n",
    "\n",
    "Before divinh into the nitty-gritty of Sagemaker training and deploy, it is crutial to make sure the training and deploy \"container\" is set up. This container will provide the most up-to-date version of GluonCV, MXNet and other essential programming environments, which enable us to achieve state-of-the-art(SOTA) model training and deployment.\n",
    "Let's take a look of the process of setting up a container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training, Batch Inference and Hosting your Algorithm in Amazon SageMaker\n",
    "\n",
    "Once you have your container packaged, you can use it to train and serve models. Let's do that with the algorithm we made above.\n",
    "\n",
    "## Set up the environment\n",
    "\n",
    "Here we specify a bucket to use and the role that will be used for working with Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the session\n",
    "\n",
    "The session remembers our connection parameters to Amazon SageMaker. We'll use it to perform all of our SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model\n",
    "\n",
    "In order to use Amazon SageMaker to fit our algorithm, we'll create an `Estimator` that defines how to use the container to train. This includes the configuration we need to invoke SageMaker training:\n",
    "\n",
    "* The __container name__. This is constructed as in the shell commands above.\n",
    "* The __role__. As defined above.\n",
    "* The __instance count__ which is the number of machines to use for training.\n",
    "* The __instance type__ which is the type of machine to use for training.\n",
    "* The __output path__ determines where the model artifact will be written.\n",
    "* The __session__ is the SageMaker session object that we defined above.\n",
    "\n",
    "Then we use fit() on the estimator to train against the data that we uploaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "ecr_name = \"mla-cv\"\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, ecr_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to S3 bucket: https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-058295922468/sagemaker-deploy-gluoncv/data/?region=us-east-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "s3_bucket = \"sagemaker-deploy-gluoncv\"\n",
    "# model_path = \"s3://{}/{}/model\".format(sess.default_bucket(), s3_bucket)\n",
    "# os.path.join(model_path, \"model.tar.gz\")\n",
    "# model_prefix = s3_bucket + \"/model\"\n",
    "train_data_local = \"./data/minc-2500/train\"\n",
    "train_data_dir_prefix = s3_bucket + \"/data/train\"\n",
    "\n",
    "\n",
    "# model_local_path = \"model_output\"\n",
    "train_data_upload = sess.upload_data(path=train_data_local, \n",
    "#                                 bucket=s3_bucket, \n",
    "                                key_prefix=train_data_dir_prefix)\n",
    "print(\"Train input uploaded to \" + train_data_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-058295922468/sagemaker-deploy-gluoncv/model/model.tar.gz\n",
      "2020-05-14 03:48:12 Starting - Starting the training job...\n",
      "2020-05-14 03:48:15 Starting - Launching requested ML instances......\n",
      "2020-05-14 03:49:20 Starting - Preparing the instances for training...\n",
      "2020-05-14 03:49:58 Downloading - Downloading input data...\n",
      "2020-05-14 03:50:33 Training - Downloading the training image...\n",
      "2020-05-14 03:51:08 Uploading - Uploading generated training model\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mFilling weights from resnet18_v1b\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/models/resnet18_v1b-2d9d980c.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet18_v1b-2d9d980c.zip...\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/42432 [00:00<?, ?KB/s]#015  0%|          | 170/42432 [00:00<00:38, 1107.82KB/s]#015  2%|2         | 883/42432 [00:00<00:28, 1434.15KB/s]#015  8%|7         | 3251/42432 [00:00<00:19, 1996.95KB/s]#015 15%|#5        | 6562/42432 [00:00<00:12, 2780.90KB/s]#015 24%|##4       | 10295/42432 [00:00<00:08, 3834.19KB/s]#015 38%|###8      | 16258/42432 [00:00<00:04, 5330.52KB/s]#015 54%|#####3    | 22829/42432 [00:00<00:02, 7359.00KB/s]#015 70%|######9   | 29677/42432 [00:00<00:01, 10049.99KB/s]#015 84%|########4 | 35693/42432 [00:01<00:00, 13397.50KB/s]#015100%|#########9| 42328/42432 [00:01<00:00, 17614.77KB/s]#01542433KB [00:01, 37707.07KB/s]                           \u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2020-05-14 03:51:19 Completed - Training job completed\n",
      "Training seconds: 81\n",
      "Billable seconds: 81\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "train_dir = \"data/minc-2500/train\"\n",
    "hyperparameters = {'epochs': 1, \n",
    "                   'model_name': 'resnet18_v1b'}\n",
    "instance_type = 'ml.c4.2xlarge'  # 'ml.p2.xlarge'\n",
    "s3_path = \"s3://{}/{}/model\".format(sess.default_bucket(), s3_bucket)\n",
    "model_path = os.path.join(s3_path, \"model.tar.gz\")\n",
    "print(model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifier = Estimator(role=role, \n",
    "                       sagemaker_session=sess,\n",
    "                       image_name=ecr_image, \n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type=instance_type,\n",
    "                       hyperparameters=hyperparameters,\n",
    "#                        checkpoint_local_path=\"model_output/\", \n",
    "                       output_path=s3_path\n",
    "                       )\n",
    "# train_data_upload = model_upload\n",
    "classifier.fit(train_data_upload)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform\n",
    "Here we simply use a demo image for transform input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo input uploaded to s3://sagemaker-us-east-1-058295922468/sagemaker-deploy-gluoncv/data/test/cat1.jpg\n"
     ]
    }
   ],
   "source": [
    "demo_dir = \"data/demo\"\n",
    "test_image = \"cat1.jpg\"\n",
    "sample_inference_input_prefix = s3_bucket + \"/data/test\"\n",
    "\n",
    "demo_input = sess.upload_data(os.path.join(demo_dir, test_image), \n",
    "                                   key_prefix=sample_inference_input_prefix) \n",
    "print(\"Demo input uploaded to \" + demo_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "\n",
    "Deploying the model to Amazon SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count, instance type, and optionally serializer and deserializer functions. These are used when the resulting predictor is created on the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# from sagemaker.predictor import csv_serializer\n",
    "\n",
    "model = classifier.create_model()\n",
    "predictor = classifier.deploy(1, 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some data and use it for a prediction\n",
    "\n",
    "In order to do some predictions, we'll use a demo jpeg image to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lynx], with probability 0.253.\n",
      "[Egyptian cat], with probability 0.252.\n",
      "[tiger cat], with probability 0.106.\n",
      "[tabby], with probability 0.063.\n",
      "[soft-coated wheaten terrier], with probability 0.041.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(demo_dir, test_image), 'rb') as f:\n",
    "    x = f.read()\n",
    "    print(predictor.predict(x, initial_args={'ContentType':'image/jpeg'}).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup Endpoint\n",
    "\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
